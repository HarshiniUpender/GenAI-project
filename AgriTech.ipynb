{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify,render_template,redirect,url_for,send_file\n",
    "from openai import AzureOpenAI\n",
    "import tiktoken\n",
    "import os\n",
    "import http.server\n",
    "import json\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from flask_cors import CORS\n",
    "from io import BytesIO\n",
    " \n",
    " \n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "  api_version = \"2024-02-01\"\n",
    ")\n",
    " \n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "\n",
    "with open('data.txt','r') as file:\n",
    "    text = file.read()\n",
    "with open('promptData.txt','r') as file:\n",
    "    promptData = file.read()\n",
    "\n",
    "\n",
    "@app.route('/answer', methods=['POST','OPTIONS'])\n",
    "def answer():\n",
    "    radio = request.form['radioAnswer']\n",
    "    if request.form['targetLang'] != '':\n",
    "        targetLang = request.form['targetLang']\n",
    "    else:\n",
    "         targetLang = 'english'\n",
    "    if radio == 'on':\n",
    "         answer = suggest(targetLang)\n",
    "         return jsonify({'result': { \"answer\": answer}})\n",
    "        \n",
    "    else:\n",
    "          question = request.form['question']\n",
    "          answer = chunking(question,text,targetLang)\n",
    "          return jsonify({'result': {\"question\": question, \"answer\": answer}})\n",
    "         \n",
    "         \n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def chunking(queries,text,targetLang):\n",
    "  llm_deployment_name=\"gpt-35-turbo\"\n",
    "  embeddings_deployment_name=\"text-embedding-ada-002\"\n",
    "\n",
    "  def completion(prompt, llm_deployment_name):\n",
    "        response = client.chat.completions.create(\n",
    "            model=llm_deployment_name,\n",
    "            messages=prompt,\n",
    "            )\n",
    "        return response.choices[0].message.content\n",
    " \n",
    "  def get_embedding(text, embeddings_deployment_name):\n",
    "        response = client.embeddings.create(\n",
    "            input = text,  # text input to embed goes here\n",
    "            model=embeddings_deployment_name\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "\n",
    "  def cosine_similarity(embedding1, embedding2):\n",
    "        dot_product = sum(embedding1[i] * embedding2[i] for i in range(len(embedding1)))\n",
    "        magnitude1 = sum(x**2 for x in embedding1)**0.5\n",
    "        magnitude2 = sum(x**2 for x in embedding2)**0.5\n",
    "        return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "  data=text\n",
    "  chunk_size=4096\n",
    "  overlap=0\n",
    "  def overlap_chunks(data, chunk_size, overlap):\n",
    "        chunks = []\n",
    "        start = 0\n",
    "        while start < len(data):\n",
    "            end = min(start + chunk_size, len(data))\n",
    "            chunks.append(str(data[start:end]))\n",
    "            start += chunk_size - overlap\n",
    "        return chunks\n",
    "   \n",
    "  ChunksList = overlap_chunks(data, chunk_size, overlap)\n",
    "  Embedded_chunks=[]\n",
    "  for i in ChunksList:\n",
    "        Embedded_chunks.append(get_embedding(i, embeddings_deployment_name))\n",
    "  query=queries\n",
    "  query_embedding=get_embedding(query,embeddings_deployment_name)\n",
    "    \n",
    "  Distance=[]\n",
    "  for i in Embedded_chunks:\n",
    "        Distance.append(cosine_similarity(i, query_embedding))\n",
    "        min_value = max(Distance)\n",
    "  index = Distance.index(min_value)\n",
    "  Prompt_paragraph=ChunksList[index]\n",
    "  if len(ChunksList) >= 3:\n",
    "        temp = Distance.copy()\n",
    "        temp.sort()\n",
    "        temp.reverse()\n",
    "        for i in range(0,5):\n",
    "            t1 = Distance.index(temp[i])\n",
    "            Prompt_paragraph=Prompt_paragraph+ChunksList[t1]\n",
    "  elif len(ChunksList) == 2:\n",
    "        temp = Distance.copy()\n",
    "        temp.sort()\n",
    "        temp.reverse()\n",
    "        t1 = temp.index(temp[0])\n",
    "        t2 = temp.index(temp[1])\n",
    "        Prompt_paragraph=ChunksList[t1]+ChunksList[t2]\n",
    "  numOfToken=num_tokens_from_string(text, \"cl100k_base\")\n",
    "\n",
    "  prompt = f\"\"\"Please use the information provided below to answer complete question in {targetLang} language\n",
    "  Additional information:\n",
    "  \\\"\\\"\\\"\n",
    "  {Prompt_paragraph}\n",
    "  \\\"\\\"\\\"\n",
    "  Question:{query}\"\"\"\n",
    "\n",
    "  num_of_token=num_tokens_from_string(prompt, \"cl100k_base\")\n",
    "  messages=[{'role': 'user', 'content': prompt}]\n",
    " \n",
    "  response = completion(messages, llm_deployment_name)\n",
    "  return response\n",
    " \n",
    "\n",
    "def suggest(selected_language):\n",
    "    prompt = f\"{promptData}+Please give the information in {selected_language} language\"\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\", \n",
    "    messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        )\n",
    "    answer = response.choices[0].message.content\n",
    "    return answer\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install flask flask_cors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
